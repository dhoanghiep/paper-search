# Multi-Source Paper Scraping Guide

**Updated:** 2025-11-27  
**Supported Sources:** arXiv, bioRxiv, PubMed

---

## Quick Reference

### CLI Usage

```bash
# arXiv - Computer Science papers
python -m app.cli --source=arxiv --max-results=10

# bioRxiv - Biology preprints
python -m app.cli --source=biorxiv --max-results=10

# PubMed - Medical research
python -m app.cli --source=pubmed --max-results=10 --query="cancer treatment"
```

### API Usage

```bash
# arXiv
curl -X POST "http://localhost:8000/jobs/scrape?source=arxiv&max_results=10"

# bioRxiv
curl -X POST "http://localhost:8000/jobs/scrape?source=biorxiv&max_results=10"

# PubMed with query
curl -X POST "http://localhost:8000/jobs/scrape?source=pubmed&max_results=10&query=diabetes"
```

---

## Source Comparison

| Feature | arXiv | bioRxiv | PubMed |
|---------|-------|---------|--------|
| **Field** | Physics, CS, Math | Biology | Medicine |
| **Type** | Preprints | Preprints | Published |
| **API** | XML | JSON | XML |
| **ID Format** | 2311.12345 | DOI | PMID:12345678 |
| **Query Support** | Keywords | Date range | Advanced queries |
| **Rate Limit** | 3/sec | 2/sec | 3/sec |

---

## Example Workflows

### 1. Scrape from All Sources

```bash
# Get 5 papers from each source
curl -X POST "http://localhost:8000/jobs/scrape?source=arxiv&max_results=5"
curl -X POST "http://localhost:8000/jobs/scrape?source=biorxiv&max_results=5"
curl -X POST "http://localhost:8000/jobs/scrape?source=pubmed&max_results=5&query=cancer"

# Check total
curl http://localhost:8000/jobs/status
```

### 2. Process All Papers

```bash
# Auto-classify and summarize
curl -X POST "http://localhost:8000/jobs/process-sync?limit=20"
```

### 3. Generate Report

```bash
# View all papers
curl http://localhost:8000/papers/
```

---

## PubMed Query Tips

**Basic:**
- `cancer` - Single term
- `cancer OR diabetes` - Multiple terms
- `cancer AND treatment` - Both required

**Field-specific:**
- `cancer[Title]` - In title only
- `cancer[Title/Abstract]` - In title or abstract
- `cancer[MeSH Terms]` - Medical subject heading

**Date filters:**
- `cancer AND 2024[PDAT]` - Published in 2024
- `cancer AND 2023:2024[PDAT]` - Date range

**Complex:**
```
(cancer OR tumor) AND (treatment OR therapy) AND 2024[PDAT]
```

---

## Database Schema

All papers stored in same table with unified fields:

```python
Paper:
  - arxiv_id: str  # Stores arXiv ID, DOI, or PMID
  - title: str
  - authors: str
  - abstract: str
  - published_date: datetime
  - pdf_url: str
  - summary: str  # Generated by AI
```

**Identifier formats:**
- arXiv: `2311.12345`
- bioRxiv: `10.1101/2024.11.20.624567`
- PubMed: `PMID:39012345`

---

## Testing

```bash
# Test each source
curl -X POST "http://localhost:8000/jobs/scrape?source=arxiv&max_results=2"
curl -X POST "http://localhost:8000/jobs/scrape?source=biorxiv&max_results=2"
curl -X POST "http://localhost:8000/jobs/scrape?source=pubmed&max_results=2&query=AI"

# Verify papers added
curl http://localhost:8000/papers/ | jq '.[] | {id: .arxiv_id, title: .title}'
```

---

## Next Steps

- Add source field to distinguish repositories
- Create unified search interface
- Add more sources (Semantic Scholar, Europe PMC)
- Schedule automatic scraping from all sources
